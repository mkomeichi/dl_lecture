{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3回 演習課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1．単純パーセプトロンの実装と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.層をLayerクラスとして定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_dim,out_dim,function):\n",
    "        self.W = np.zeros((in_dim,out_dim))\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.function = function\n",
    "\n",
    "    #forward propagation\n",
    "    def fprop(self,x):\n",
    "        u = \n",
    "        z = \n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.ステップ関数\n",
    "\n",
    "ヒント：ステップ関数\n",
    "\n",
    "* $u\\geq0$のとき，$f(u)=+1$\n",
    "* $u<0$のとき，$f(u)=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.データセットの設定とレイヤーインスタンス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OR\n",
    "train_X = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "train_y = np.array([[1],[1],[-1],[1]])\n",
    "test_X,test_y = train_X,train_y\n",
    "\n",
    "layer = Layer(2,1,step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.train関数とtest関数\n",
    "\n",
    "ヒント：パーセプトロン学習則\n",
    "\n",
    "$y_n\\neq d_n$のとき\n",
    "* $w^{(t+1)}=w^{(t)}-\\epsilon x_nd_n$　\n",
    "* $b^{(t+1)}=b^{(t)}-\\epsilon d_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x,d,eps=1):\n",
    "    #forward propagation\n",
    "    y = layer.fprop(x)\n",
    "\n",
    "    #update parameters\n",
    "    if :\n",
    "        layer.W = \n",
    "        layer.b = \n",
    "\n",
    "def test(x):\n",
    "    y = layer.fprop(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.パラメータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#epoch\n",
    "for epoch in range(10):\n",
    "    #online learning\n",
    "    for x,y in zip(train_X,train_y):\n",
    "        train(x[np.newaxis,:],y[np.newaxis,:],eps=1)\n",
    "pred_y = test(test_X)\n",
    "print pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##課題2．活性化関数とその微分の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.シグモイド関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return\n",
    "def diff_sigmoid(x):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "２.ソフトマックス関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return\n",
    "def diff_softmax(x):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.tanh関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return\n",
    "def diff_tanh(x):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題3．多層パーセプトロンの実装と学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.Layerクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_dim,out_dim,function,diff_function):\n",
    "        #Xavier\n",
    "        self.W = np.random.uniform(\n",
    "                                    low=-np.sqrt(6./(in_dim+out_dim)), \n",
    "                                    high=np.sqrt(6./(in_dim+out_dim)), \n",
    "                                    size=(in_dim, out_dim))\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.function = function\n",
    "        \n",
    "        self.diff_function = diff_function\n",
    "        self.u     = None\n",
    "        self.delta = None\n",
    "\n",
    "    #forward propagation\n",
    "    def fprop(self,x):\n",
    "        u = \n",
    "        z = \n",
    "        self.u = u\n",
    "        return z\n",
    "\n",
    "    #back propagation\n",
    "    def bprop(self,delta,W):\n",
    "        delta = \n",
    "        self.delta = delta\n",
    "        return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.ネットワーク全体の順伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fprops(layers, x):\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.ネットワーク全体の誤差逆伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bprops(layers, delta):\n",
    "    for i,layer in enumerate(layers[::-1]):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.データセットの設定とネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XOR\n",
    "train_X = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "train_y = np.array([[1],[1],[0],[0]])\n",
    "test_X,test_y = train_X,train_y\n",
    "\n",
    "layers = [Layer(2,3,sigmoid,diff_sigmoid),\n",
    "          Layer(3,1,sigmoid,diff_sigmoid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.train関数とtest関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X,d,eps=1):\n",
    "    #forward propagation\n",
    "    y = fprops(layers,X)\n",
    "        \n",
    "    #cost function & delta\n",
    "    cost = \n",
    "    delta = \n",
    "    \n",
    "    #back propagation\n",
    "    bprops(layers,delta)\n",
    "\n",
    "    #update parameters\n",
    "    z = X\n",
    "    for layer in layers:\n",
    "        dW = \n",
    "        db = \n",
    "\n",
    "        layer.W = layer.W - eps*dW\n",
    "        layer.b = layer.b - eps*db\n",
    "\n",
    "        z = layer.fprop(z)\n",
    "        \n",
    "    #train cost\n",
    "    y = fprops(layers,X)\n",
    "    cost = \n",
    "    \n",
    "    return cost\n",
    "\n",
    "def test(X,d):\n",
    "    #test cost\n",
    "    y = fprops(layers,X)\n",
    "    cost = \n",
    "    return cost,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.パラメータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#epoch\n",
    "for epoch in range(100):\n",
    "    #online learning\n",
    "    train_X, train_y = shuffle(train_X, train_y)\n",
    "    for x,y in zip(train_X,train_y):\n",
    "        train(x[np.newaxis,:],y[np.newaxis,:])\n",
    "    cost,pred_y = test(test_X,test_y)\n",
    "print pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題．MNISTデータセットを多層パーセプトロンで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データはmnist_x,mnist_yで与えられます\n",
    "    - mnsit_xとmnist_yをtrain_X,train_yとtest_X,test_yに分けて，モデルを学習してください\n",
    "\n",
    "ヒント\n",
    "* 出力yはone-of-k表現\n",
    "* 最終層の活性化関数はsoftmax関数，誤差関数は多クラス交差エントロピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "X, y = shuffle(mnist.data, mnist.target)\n",
    "X = X / 255.0\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルに解答を書いて提出してください\n",
    "- レイヤークラスなど，必要なものは全て書いてください.\n",
    "- システム側では，pred_yの結果から評価します.\n",
    "- test関数の戻り値（pred_y）は，one-of-k表現（one-hot）のままで大丈夫です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
