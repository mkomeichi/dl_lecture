{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan\n",
    "\n",
    "Theano ではループのために For 文ではなく、Scan というものを使います　　\n",
    "少しややこしいので、簡単な例を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "##Suppose you have a sequence [1, 2, 3, 4, 5] let's define identity function with scan\n",
    "x = T.fvector(\"x\")\n",
    "\n",
    "def step(x):\n",
    "    return x\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=None\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([1, 2, 3, 4, 5]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   3.   6.  10.  15.]\n"
     ]
    }
   ],
   "source": [
    "##Next we define accumulation function\n",
    "x = T.fvector(\"x\")\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=0.0, #Initial value for h\n",
    "                       #go_backwards=True #you might use it for bi-directional RNNs\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([1, 2, 3, 4, 5]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.]\n",
      " [  2.   4.   6.   8.  10.]\n",
      " [  3.   6.   9.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "## Let's do the same thing with matrix, accumulation over column\n",
    "x = T.fmatrix(\"x\")\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=numpy.array([0., 0., 0., 0., 0.]) #Initial value for h, it's better to use T.alloc().\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   6.   9.  12.  15.]\n",
      " [  3.   6.   9.  12.  15.]\n",
      " [  3.   6.   9.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "## Advanced :: take previous inputs\n",
    "x = T.fmatrix(\"x\")\n",
    "\n",
    "def step(x, h_tm1, h_tm2):\n",
    "    return x + h_tm1 + h_tm2\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=[ dict(input= x, taps = [0, -1, -2])],\n",
    "                       outputs_info=None #Initial value for h\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5],[1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [宿題] POS Tagging\n",
    "\n",
    "文が与えられた時、その品詞を予測する RNN を学習します。\n",
    "\n",
    "word2index は単語をIDに変換する辞書、tag2index は品詞をIDに変換する辞書です。  \n",
    "train_data, dev_data には文と品詞タグのペアが入っています。  \n",
    "文の長さと品詞タグの長さは必ず同じです。\n",
    "\n",
    "encode_dataset を使うと単語と品詞をIDに変換することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def load_data(file_path):\n",
    "    dataset = []\n",
    "    vocab, tag = set(), set()\n",
    "    for line in open(file_path):\n",
    "        instance = [ l.strip().split() for l in line.split('|||') ]\n",
    "        vocab.update(instance[0])\n",
    "        tag.update(instance[1])\n",
    "        dataset.append(instance)\n",
    "    return dataset, vocab, tag\n",
    "\n",
    "def encode_dataset(dataset, word2index, tag2index):\n",
    "    X, y = [], []\n",
    "    vocab = set(word2index.keys())\n",
    "    for sentence, tags in dataset:\n",
    "        X.append([ word2index[word] if word in vocab else word2index['<unk>'] for word in sentence])\n",
    "        y.append([ tag2index[tag] for tag in tags])\n",
    "    return X, y\n",
    "\n",
    "train_data, train_vocab, train_tags = load_data('train.unk')\n",
    "special_words = set(['<unk>'])\n",
    "\n",
    "word2index = dict(map(lambda x: (x[1], x[0]), enumerate(train_vocab | special_words)))\n",
    "tag2index  = dict(map(lambda x: (x[1], x[0]), enumerate(train_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "train_data, dev_data = train_data[:train_size//10 * 8], train_data[train_size//10 * 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In IN\n",
      "an DT\n",
      "Oct. NNP\n",
      "19 CD\n",
      "review NN\n",
      "of IN\n",
      "`` ``\n",
      "The DT\n",
      "Misanthrope NN\n",
      "'' ''\n",
      "at IN\n",
      "Chicago NNP\n",
      "'s POS\n",
      "Goodman NNP\n",
      "Theatre NNP\n",
      "`` ``\n",
      "Revitalized VBN\n",
      "Classics NNS\n",
      "Take VBP\n",
      "the DT\n",
      "Stage NN\n",
      "in IN\n",
      "Windy NNP\n",
      "City NNP\n",
      ", ,\n",
      "'' ''\n",
      "Leisure NN\n",
      "& CC\n",
      "Arts NNS\n",
      ", ,\n",
      "the DT\n",
      "role NN\n",
      "of IN\n",
      "Celimene NNP\n",
      ", ,\n",
      "played VBN\n",
      "by IN\n",
      "Kim NNP\n",
      "Cattrall NNP\n",
      ", ,\n",
      "was VBD\n",
      "mistakenly RB\n",
      "attributed VBN\n",
      "to TO\n",
      "Christina NNP\n",
      "Haag NNP\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word, tag in zip(train_data[0][0], train_data[0][1]):\n",
    "    print word, tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルを完成させて提出してください　　\n",
    "\n",
    "今回の入力は単語のID列（ベクトル x）と品詞のID列 (ベクトル y)です。  \n",
    "Projection レイヤーを使って、単語をベクトルに変換します。  \n",
    "その後、RNN に入力し、その出力値をSotfmax関数を使って確率分布に変換します。  \n",
    "予測は画像の時とおなじく、最大の確率を持つクラスを予測とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "train_data, dev_data = train_data[:train_size//10 * 8], train_data[train_size//10 * 8:]\n",
    "\n",
    "train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "dev_X  , dev_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "\n",
    "rng = numpy.random.RandomState(42)\n",
    "trng = RandomStreams(42)\n",
    "\n",
    "def sharedX(X, dtype=\"float32\"):\n",
    "    return theano.shared(numpy.asarray(X, dtype=dtype))\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.params = []\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.params = [ self.W ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = #WRITE ME\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.b = sharedX(rng.randn(out_dim,) * scale)\n",
    "        self.params = [ self.W, self.b ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = T.dot(x, self.W)+self.b\n",
    "        return h\n",
    "\n",
    "    \n",
    "class RNN:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.scale = scale\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "        ## 重みの次元を決める。\n",
    "        self.Wx = sharedX(rng.randn(#WRITE ME, ) * scale)\n",
    "        self.Wh = sharedX(rng.randn(#WRITE ME, ) * scale)\n",
    "        self.bh = sharedX(rng.randn(#WRITE ME, ) * scale)\n",
    "        ## Initial State をどのように初期化するか\n",
    "        self.h0 = sharedX(#WEIRE ME）\n",
    "\n",
    "        self.output_info = [ self.h0 ]\n",
    "        self.params = [  ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        def step(u_t, h_tm1):\n",
    "            h = #WRITE ME\n",
    "            return h\n",
    "        \n",
    "        ## Scan の方法を考える \n",
    "        h, _ = theano.scan(#WRITE ME)\n",
    "        return h\n",
    "    \n",
    "\n",
    "def sgd(cost, params, lr):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        ## Advanced Gradient Glip を実装する　（必須ではない）\n",
    "        #WRITE ME\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n",
    "\n",
    "def prop(layers, x):\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            layer_out = layer.fprop(x)\n",
    "        else:\n",
    "            layer_out = layer.fprop(layer_out)\n",
    "    return layer_out\n",
    "\n",
    "\n",
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        params += layer.params\n",
    "    return params\n",
    "\n",
    "\n",
    "### build Model + Train\n",
    "vocab_size = len(word2index)\n",
    "hid_dim    = 100\n",
    "out_dim    = len(tag2index)\n",
    "\n",
    "x, t = T.lvector(\"x\"), T.lvector(\"t\")\n",
    "\n",
    "layers = [\n",
    "    　 # レイヤー構成を決める\n",
    "    ]\n",
    "\n",
    "prob = prop(layers, x) \n",
    "cost = # Loss function を決める　\n",
    "pred = #　予測した確率から、予測値を決める\n",
    "\n",
    "## Collect Parameters\n",
    "params = get_params(layers) \n",
    "\n",
    "## Define update graph\n",
    "updates = sgd(cost, params, lr=numpy.float32(0.01)) \n",
    "\n",
    "## Compile Function\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "valid = theano.function([x,t], [cost, pred])\n",
    "test  = theano.function([x]　,　pred)\n",
    "\n",
    "epochs = 100\n",
    "## Train\n",
    "for epoch in range(epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        cost = train(instance_x, instance_y)\n",
    "        if i % 1000 == 0:\n",
    "            print \"EPOCH:: %i, Iteration %i, cost: %.3f\"%(epoch+1, i, cost)\n",
    "    \n",
    "    dev_true, dev_pred = [], []\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(dev_X, dev_y)):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        dev_pred += list(pred) # 予測結果はベクトル\n",
    "        dev_true += instance_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
